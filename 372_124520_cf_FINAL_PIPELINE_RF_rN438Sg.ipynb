{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df.drop('enrollee_id',inplace=True,axis=1)\n",
    "    \n",
    "    df.company_type.fillna(value='missing',inplace=True)\n",
    "    df.company_size.fillna(value='missing',inplace=True)\n",
    "    df.gender.fillna(value='missing',inplace=True)\n",
    "    df.major_discipline.fillna(value='missing',inplace=True)\n",
    "    df.education_level.fillna(value='missing',inplace=True)\n",
    "    df.last_new_job.fillna(value='missing',inplace=True)\n",
    "    df.enrolled_university.fillna(value='missing',inplace=True)\n",
    "    df.experience.fillna(value=-99,inplace=True)\n",
    "    \n",
    "    #PROCESSING CITY COL\n",
    "    a=sorted(df.city.unique())\n",
    "    b=[]\n",
    "    for i in a:\n",
    "        b.append(i[5:])\n",
    "    dic=dict(zip(a,b))\n",
    "    df['city']=df['city'].map(dic).astype(int)\n",
    "\n",
    "    #LABEL ENCODING ORDINAL FEATURES\n",
    "    education=['Primary School','High School','Graduate','Masters','Phd','missing']\n",
    "    educationmapping=dict(zip(education,[1,2,3,4,5,-99]))\n",
    "    df['education_level_val']=df['education_level'].map(educationmapping).astype(int)\n",
    "    df.drop('education_level',axis=1,inplace=True)\n",
    "\n",
    "    company_size=['<10','10/49','50-99','100-500','500-999','1000-4999','5000-9999','10000+','missing']\n",
    "    #company_sizemapping=dict(zip(company_size,[5,25,75,250,750,2500,7500,1250,-99]))\n",
    "    company_sizemapping=dict(zip(company_size,[1,2,3,4,5,6,7,8,-99]))    \n",
    "    df['company_size_val']=df['company_size'].map(company_sizemapping).astype(int)\n",
    "    df.drop('company_size',axis=1,inplace=True)\n",
    "\n",
    "    last_new_job=['never','1', '2', '3', '4', '>4', 'missing']\n",
    "    last_new_jobmapping=dict(zip(last_new_job,[0,1,2,3,4,5,-99]))\n",
    "    df['last_new_job_val']=df['last_new_job'].map(last_new_jobmapping).astype(int)\n",
    "    df.drop('last_new_job',axis=1,inplace=True)\n",
    "\n",
    "    enrolled_university=['no_enrollment','Part time course', 'Full time course', 'missing']\n",
    "    enrolled_universitymapping=dict(zip(enrolled_university,[1,2,3,-99]))\n",
    "    df['enrolled_university_val']=df['enrolled_university'].map(enrolled_universitymapping).astype(int)\n",
    "    df.drop('enrolled_university',axis=1,inplace=True)\n",
    "\n",
    "    #lABEL ENCODING BINARY FEATURE\n",
    "    relevent_experience=sorted(df['relevent_experience'].unique())\n",
    "    relevent_experiencemapping=dict(zip(relevent_experience,range(0,len(relevent_experience))))\n",
    "    df['relevent_experience_val']=df['relevent_experience'].map(relevent_experiencemapping).astype(int)\n",
    "    df.drop('relevent_experience',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    #FREQUENCY ENCODING NOMINAL CATEGORICAL FEATURES\n",
    "    train=pd.read_csv('train_jqd04QH.csv')\n",
    "    test=pd.read_csv('test_GYi4Gz5.csv')\n",
    "    total=train.append(test)\n",
    "    \n",
    "    total.company_type.fillna(value='missing',inplace=True)\n",
    "    total.gender.fillna(value='missing',inplace=True)\n",
    "    total.major_discipline.fillna(value='missing',inplace=True)\n",
    "    \n",
    "    encoding=total.groupby('company_type').size()\n",
    "    encoding/=len(total)\n",
    "    #encoding=df.groupby('company_type').size()\n",
    "    #encoding/=len(df)\n",
    "    df['company_type_freq_enc']=df['company_type'].map(encoding)\n",
    "    df.drop('company_type',axis=1,inplace=True)\n",
    "\n",
    "    encoding=total.groupby('gender').size()\n",
    "    encoding/=len(total)\n",
    "    df['gender_freq_enc']=df['gender'].map(encoding)\n",
    "    df.drop('gender',axis=1,inplace=True)\n",
    "\n",
    "    encoding=total.groupby('major_discipline').size()\n",
    "    encoding/=len(total)\n",
    "    df['major_discipline_enc']=df['major_discipline'].map(encoding)\n",
    "    df.drop('major_discipline',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    #CLEANING COL EXPERIENCE\n",
    "    df.loc[df.experience=='<1','experience']=0\n",
    "    df.loc[df.experience=='>20','experience']=25\n",
    "    df['experience']=df.experience.astype(int)\n",
    "    \n",
    "    \n",
    "    train=pd.read_csv('train_jqd04QH.csv')\n",
    "    test=pd.read_csv('test_GYi4Gz5.csv')\n",
    "    total=train.append(test)\n",
    "    \n",
    "    total.experience.fillna(value=-99,inplace=True)\n",
    "    total.loc[total.experience=='<1','experience']=0\n",
    "    total.loc[total.experience=='>20','experience']=25\n",
    "    total['experience']=total.experience.astype(int)\n",
    "    \n",
    "    unique_experience_hours=total.experience.unique()\n",
    "    dic={}\n",
    "    for i in unique_experience_hours:\n",
    "        s=total[total.experience==i].city_development_index.sum()\n",
    "        l=len(total[total.experience==i])\n",
    "        avg=float(s/l)\n",
    "        dic[i]=avg\n",
    "    df['avg_city_development_index_wrt_experience']=df['experience'].map(dic) \n",
    "    \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_train(train):\n",
    "\n",
    "      \n",
    "    #experience\n",
    "    c=pd.crosstab(train.experience,train.target)\n",
    "    c['experience']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_experience']=c['want']-c['notwant']\n",
    "    dic2=dict(zip(c['experience'],c['target_diff_experience']))\n",
    "    train['target_diff_experience']=train['experience'].map(dic2).astype(int)\n",
    "\n",
    "    \n",
    "    #city_development_index\n",
    "    c=pd.crosstab(train.city_development_index,train.target)\n",
    "    c['city_development_index']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_city_development_index']=c['want']-c['notwant']\n",
    "    dic3=dict(zip(c['city_development_index'],c['target_diff_city_development_index']))\n",
    "    train['target_diff_city_development_index']=train['city_development_index'].map(dic3).astype(int)\n",
    "\n",
    "    \n",
    "    \n",
    "    #city\n",
    "    c=pd.crosstab(train.city,train.target)\n",
    "    c['city']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_city']=c['want']-c['notwant']\n",
    "    dic4=dict(zip(c['city'],c['target_diff_city']))\n",
    "    train['target_diff_city']=train['city'].map(dic4).astype(int)\n",
    "    \n",
    "    #company_size_val\n",
    "    c=pd.crosstab(train.company_size_val,train.target)\n",
    "    c['company_size_val']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_company_size_val']=c['want']-c['notwant']\n",
    "    dic5=dict(zip(c['company_size_val'],c['target_diff_company_size_val']))\n",
    "    train['target_diff_company_size_val']=train['company_size_val'].map(dic5).astype(int)\n",
    "\n",
    "    \n",
    "    #last_new_job_val\n",
    "    c=pd.crosstab(train.last_new_job_val,train.target)\n",
    "    c['last_new_job_val']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_last_new_job_val']=c['want']-c['notwant']\n",
    "    dic8=dict(zip(c['last_new_job_val'],c['target_diff_last_new_job_val']))\n",
    "    train['target_diff_last_new_job_val']=train['last_new_job_val'].map(dic8).astype(int)\n",
    "    \n",
    "    #major_discipline_enc\n",
    "    c=pd.crosstab(train.major_discipline_enc,train.target)\n",
    "    c['major_discipline_enc']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_major_discipline_enc']=c['want']-c['notwant']\n",
    "    dic9=dict(zip(c['major_discipline_enc'],c['target_diff_major_discipline_enc']))\n",
    "    train['target_diff_major_discipline_enc']=train['major_discipline_enc'].map(dic9).astype(int)\n",
    "    \n",
    "    #enrolled_university_val\n",
    "    c=pd.crosstab(train.enrolled_university_val,train.target)\n",
    "    c['enrolled_university_val']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_diff_enrolled_university_val']=c['want']-c['notwant']\n",
    "    dic10=dict(zip(c['enrolled_university_val'],c['target_diff_enrolled_university_val']))\n",
    "    train['target_diff_enrolled_university_val']=train['enrolled_university_val'].map(dic10).astype(int)\n",
    "    \n",
    "\n",
    "    ###city_development_index ratio\n",
    "    c=pd.crosstab(train.city_development_index,train.target)\n",
    "    c['city_development_index']=c.index\n",
    "    c['want']=c[1]\n",
    "    c['notwant']=c[0]\n",
    "    c['target_ratio0_city_development_index']=c['notwant']/(c['want']+c['notwant'])\n",
    "    #c['target_ratio1_city_development_index']=c['want']/(c['want']+c['notwant'])\n",
    "    #c['target_ratio_diff_city_development_index']=c['target_ratio0_city_development_index']-c['target_ratio1_city_development_index']\n",
    "\n",
    "    dic103=dict(zip(c['city_development_index'],c['target_ratio0_city_development_index']))\n",
    "    train['target_ratio0_city_development_index']=train['city_development_index'].map(dic103)\n",
    "\n",
    "    \n",
    "    dic_all=[dic2,dic3,dic4,dic5,dic8,dic9,dic10,dic103]  #list1\n",
    "\n",
    "    return(train,dic_all)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_test(test,dic_all):\n",
    "    \n",
    "    (dic2,dic3,dic4,dic5,dic8,dic9,dic10,dic103)=dic_all         #list1\n",
    "\n",
    "    \n",
    "    test['target_diff_experience']=test['experience'].map(dic2).astype(int)\n",
    "\n",
    "    test['target_diff_city_development_index']=test['city_development_index'].map(dic3)\n",
    "    test.target_diff_city_development_index.fillna(value=test.target_diff_city_development_index.mean(),inplace=True)\n",
    "    \n",
    "    test['target_diff_city']=test['city'].map(dic4)\n",
    "    test.target_diff_city.fillna(value=103,inplace=True)\n",
    "    \n",
    "    test['target_diff_company_size_val']=test['company_size_val'].map(dic5)\n",
    "      \n",
    "    test['target_diff_last_new_job_val']=test['last_new_job_val'].map(dic8)\n",
    "    \n",
    "    test['target_diff_major_discipline_enc']=test['major_discipline_enc'].map(dic9)\n",
    "    \n",
    "    test['target_diff_enrolled_university_val']=test['enrolled_university_val'].map(dic10)\n",
    "    \n",
    "      \n",
    "    test['target_ratio0_city_development_index']=test['city_development_index'].map(dic103) #only for RF\n",
    "    test.target_ratio0_city_development_index.fillna(value=test.target_ratio0_city_development_index.mean(),inplace=True)\n",
    "  \n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train_jqd04QH.csv')\n",
    "test=pd.read_csv('test_GYi4Gz5.csv')\n",
    "\n",
    "train=preprocessing(train)\n",
    "test=preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,dic_all=FE_train(train)\n",
    "test=FE_test(test,dic_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['target']\n",
    "x=train\n",
    "x.drop(['target'],axis=1,inplace=True)\n",
    "x=pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ENSEMBLING RF WITH BAGGING \n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "bags=10\n",
    "seed=1\n",
    "bagged_prediction=np.zeros(test.shape[0])\n",
    "for n in range(0,bags):\n",
    "    model.set_params(random_state=seed+n,n_estimators = 50, n_jobs = -1,max_features = 2, min_samples_leaf =30,max_depth=10)\n",
    "    model.fit(x,y)\n",
    "    pred=model.predict(test)\n",
    "    bagged_prediction+=pred\n",
    "bagged_prediction/=bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the submission file\n",
    "submission=pd.read_csv(\"sample_submission_sxfcbdx.csv\")\n",
    "# Fill the is_pass variable with the predictions\n",
    "#submission['target']=pred_test\n",
    "submission['target']=bagged_prediction\n",
    "# Converting the submission file to csv format\n",
    "submission.to_csv('Verify_with_redownload_data_RF2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16548</td>\n",
       "      <td>0.316501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12036</td>\n",
       "      <td>0.073949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11061</td>\n",
       "      <td>0.299010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5032</td>\n",
       "      <td>0.062413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17599</td>\n",
       "      <td>0.097948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id    target\n",
       "0        16548  0.316501\n",
       "1        12036  0.073949\n",
       "2        11061  0.299010\n",
       "3         5032  0.062413\n",
       "4        17599  0.097948"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
